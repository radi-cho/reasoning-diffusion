{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb81a3d6-cbec-45e4-90db-cf0746c381b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar  1 13:19:38 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.230.02             Driver Version: 535.230.02   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA H100 80GB HBM3          On  | 00000000:1A:00.0 Off |                    0 |\n",
      "| N/A   26C    P0              69W / 700W |      0MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA H100 80GB HBM3          On  | 00000000:40:00.0 Off |                    0 |\n",
      "| N/A   25C    P0              69W / 700W |      0MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA H100 80GB HBM3          On  | 00000000:53:00.0 Off |                    0 |\n",
      "| N/A   24C    P0              69W / 700W |      0MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA H100 80GB HBM3          On  | 00000000:66:00.0 Off |                    0 |\n",
      "| N/A   25C    P0              70W / 700W |      0MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA H100 80GB HBM3          On  | 00000000:9C:00.0 Off |                    0 |\n",
      "| N/A   28C    P0              69W / 700W |      0MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA H100 80GB HBM3          On  | 00000000:C0:00.0 Off |                    0 |\n",
      "| N/A   24C    P0              68W / 700W |      0MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA H100 80GB HBM3          On  | 00000000:D2:00.0 Off |                    0 |\n",
      "| N/A   25C    P0              68W / 700W |      0MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA H100 80GB HBM3          On  | 00000000:E4:00.0 Off |                    0 |\n",
      "| N/A   23C    P0              67W / 700W |      0MiB / 81559MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4171c46-9dca-4178-8573-2407237a9f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  unzip zip\n",
      "0 upgraded, 2 newly installed, 0 to remove and 62 not upgraded.\n",
      "Need to get 350 kB of archives.\n",
      "After this operation, 930 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 unzip amd64 6.0-26ubuntu3.2 [175 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 zip amd64 3.0-12build2 [176 kB]\n",
      "Fetched 350 kB in 0s (1235 kB/s)\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package unzip.\n",
      "(Reading database ... 15512 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-26ubuntu3.2_amd64.deb ...\n",
      "Unpacking unzip (6.0-26ubuntu3.2) ...\n",
      "Selecting previously unselected package zip.\n",
      "Preparing to unpack .../zip_3.0-12build2_amd64.deb ...\n",
      "Unpacking zip (3.0-12build2) ...\n",
      "Setting up unzip (6.0-26ubuntu3.2) ...\n",
      "Setting up zip (3.0-12build2) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get install zip unzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e4f048e-3c97-4522-bd8b-fd762c2a3542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/persistent/joeli/zeynebnk/content/LLaDA\n"
     ]
    }
   ],
   "source": [
    "#%cd zeynebnk\n",
    "#!unzip LLaDA_eval.zip\n",
    "%cd content/LLaDA/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bf6a5b4-e274-4eec-9998-ecfccfbf6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"\"\n",
    "num_gpus = 8\n",
    "bench_data_path = \"gsm8k.txt\"\n",
    "output_dir =  \"../../outputs/\"\n",
    "remasking_method = \"low_confidence\"\n",
    "\n",
    "import subprocess\n",
    "\n",
    "def runsubprocess(cmd):\n",
    "  subprocess.run(cmd, shell=True, text=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e1651d5-348e-4f85-8294-b75a38ea739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prl_cmd = f\"python prep_parallel.py --data {dir + bench_data_path} --output_head {dir + 'chunk'} --num_gpu {num_gpus}\"\n",
    "runsubprocess(prl_cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "550c5448-0b40-4f54-ae67-7834846535ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e08ca56-30eb-4ce3-b98b-b3b66af76396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gen_batch_preds.py with args ['--filepath', 'chunk_0.txt', '--output_path', '../../outputs/_0preds.txt', '--remasking_method', 'low_confidence', '--gen_len', '256', '--steps', '128', '--block_size', '8'] on GPU 0\n",
      "Starting gen_batch_preds.py with args ['--filepath', 'chunk_1.txt', '--output_path', '../../outputs/_1preds.txt', '--remasking_method', 'low_confidence', '--gen_len', '256', '--steps', '128', '--block_size', '8'] on GPU 1\n",
      "Starting gen_batch_preds.py with args ['--filepath', 'chunk_2.txt', '--output_path', '../../outputs/_2preds.txt', '--remasking_method', 'low_confidence', '--gen_len', '256', '--steps', '128', '--block_size', '8'] on GPU 2\n",
      "Starting gen_batch_preds.py with args ['--filepath', 'chunk_3.txt', '--output_path', '../../outputs/_3preds.txt', '--remasking_method', 'low_confidence', '--gen_len', '256', '--steps', '128', '--block_size', '8'] on GPU 3\n",
      "Starting gen_batch_preds.py with args ['--filepath', 'chunk_4.txt', '--output_path', '../../outputs/_4preds.txt', '--remasking_method', 'low_confidence', '--gen_len', '256', '--steps', '128', '--block_size', '8'] on GPU 4\n",
      "Starting gen_batch_preds.py with args ['--filepath', 'chunk_5.txt', '--output_path', '../../outputs/_5preds.txt', '--remasking_method', 'low_confidence', '--gen_len', '256', '--steps', '128', '--block_size', '8'] on GPU 5\n",
      "Starting gen_batch_preds.py with args ['--filepath', 'chunk_6.txt', '--output_path', '../../outputs/_6preds.txt', '--remasking_method', 'low_confidence', '--gen_len', '256', '--steps', '128', '--block_size', '8'] on GPU 6\n",
      "Starting gen_batch_preds.py with args ['--filepath', 'chunk_7.txt', '--output_path', '../../outputs/_7preds.txt', '--remasking_method', 'low_confidence', '--gen_len', '256', '--steps', '128', '--block_size', '8'] on GPU 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/GSAI-ML/LLaDA-8B-Instruct:\n",
      "- configuration_llada.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/GSAI-ML/LLaDA-8B-Instruct:\n",
      "- configuration_llada.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/GSAI-ML/LLaDA-8B-Instruct:\n",
      "- configuration_llada.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/GSAI-ML/LLaDA-8B-Instruct:\n",
      "- configuration_llada.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/GSAI-ML/LLaDA-8B-Instruct:\n",
      "- configuration_llada.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/GSAI-ML/LLaDA-8B-Instruct:\n",
      "- modeling_llada.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/GSAI-ML/LLaDA-8B-Instruct:\n",
      "- modeling_llada.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/GSAI-ML/LLaDA-8B-Instruct:\n",
      "- modeling_llada.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/GSAI-ML/LLaDA-8B-Instruct:\n",
      "- modeling_llada.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/GSAI-ML/LLaDA-8B-Instruct:\n",
      "- modeling_llada.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/GSAI-ML/LLaDA-8B-Instruct:\n",
      "- modeling_llada.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/GSAI-ML/LLaDA-8B-Instruct:\n",
      "- modeling_llada.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/GSAI-ML/LLaDA-8B-Instruct:\n",
      "- modeling_llada.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "Downloading shards:  83%|████████▎ | 5/6 [01:05<00:13, 13.49s/it]"
     ]
    }
   ],
   "source": [
    "def run_on_gpu(script_path, gpu_id, args):\n",
    "    \"\"\"Run a Python script on a specific GPU with arguments.\"\"\"\n",
    "    env = os.environ.copy()\n",
    "    env[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "    \n",
    "    cmd = [\"python\", script_path] + args\n",
    "    print(f\"Starting {script_path} with args {args} on GPU {gpu_id}\")\n",
    "    process = subprocess.Popen(cmd, env=env)\n",
    "    return process\n",
    "\n",
    "ps = []\n",
    "for gpu_id in range(num_gpus):\n",
    "  ## ADD CODE TO MAKE RUN IN PARALLEL\n",
    "  # pred_cmd = f\"python gen_batch_preds.py --filepath {dir + 'chunk' + \"_\" + str(i) + \".txt\"} --output_path {output_dir + \"_\" + str(i) + \"preds.txt\"} --remasking_method {remasking_method}\"\n",
    "  # runsubprocess(pred_cmd)\n",
    "    \n",
    "    script_path = \"gen_batch_preds.py\"\n",
    "    args = [\n",
    "        \"--filepath\", f\"{dir}chunk_{gpu_id}.txt\", \n",
    "        \"--output_path\", f\"{output_dir}_{gpu_id}preds.txt\", \n",
    "        \"--remasking_method\", remasking_method,\n",
    "\n",
    "        \"--gen_len\",'256',\n",
    "        \"--steps\",'128',\n",
    "        \"--block_size\",'8'\n",
    "    ]\n",
    "    process = run_on_gpu(script_path, gpu_id, args)\n",
    "    ps.append(process)\n",
    "\n",
    "for p in ps:\n",
    "    p.wait()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6707e1e2-f715-4a08-afee-ec3570d4df5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_0preds.txt  _2preds.txt  _4preds.txt  _6preds.txt\n",
      "_1preds.txt  _3preds.txt  _5preds.txt  _7preds.txt\n"
     ]
    }
   ],
   "source": [
    "!ls \"../../outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7bde0dd-65af-4724-9c0c-3d47c474901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## AFTER ALL PREDS ARE GENERATED\n",
    "all_pred_data = []\n",
    "for i in range(num_gpus):\n",
    "  with open(output_dir + \"_\" + str(i) + \"preds.txt\", \"r\") as f:\n",
    "    all_pred_data += eval(f.read())\n",
    "\n",
    "with open(output_dir + \"_all_preds.txt\", \"w\") as f:\n",
    "    f.write(str(all_pred_data))\n",
    "\n",
    "eval_cmd = f\"python evaluate_gsm.py --pred_data {output_dir + '_all_preds.txt'} --output_dir {output_dir}\"\n",
    "runsubprocess(eval_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca75267-b746-4bc4-8ec0-fef88cfc7e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
