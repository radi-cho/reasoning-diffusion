{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "419db978-5d94-44c2-ac52-61516d1307db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e56f41287bb49c3b3512bb8bbbf6458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LLaDAModelLM were not initialized from the model checkpoint at ./LLaDA-8B-Instruct and are newly initialized: ['model.transformer.mask_head.bias', 'model.transformer.mask_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "device = 'cuda'\n",
    "model = AutoModel.from_pretrained('./LLaDA-8B-Instruct', trust_remote_code=True, torch_dtype=torch.bfloat16, use_cache=False).to(device).eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained('./LLaDA-8B-Instruct', trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2a0762f-a98e-4bf6-b9e0-3dc148125799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0199,  0.0060,  0.0029,  ..., -0.0194,  0.0100, -0.0247]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "mask_head = model.model.transformer.mask_head\n",
    "torch.nn.init.kaiming_uniform_(mask_head.weight, nonlinearity='linear')\n",
    "if mask_head.bias is not None:\n",
    "    torch.nn.init.zeros_(mask_head.bias)\n",
    "print(mask_head.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdd05b52-c4c6-4018-a253-dcbb3b7b85f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate import generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad3e6114-0508-46fb-995d-c84511228d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************\n",
      "**  Answer Length: 128  |  Sampling Steps: 128  **\n",
      "******************************************************************\n",
      "tensor([19], device='cuda:0')\n",
      "tensor([21], device='cuda:0')\n",
      "tensor([20], device='cuda:0')\n",
      "tensor([18], device='cuda:0')\n",
      "tensor([17], device='cuda:0')\n",
      "tensor([22], device='cuda:0')\n",
      "tensor([29], device='cuda:0')\n",
      "tensor([30], device='cuda:0')\n",
      "tensor([31], device='cuda:0')\n",
      "tensor([33], device='cuda:0')\n",
      "tensor([35], device='cuda:0')\n",
      "tensor([38], device='cuda:0')\n",
      "tensor([39], device='cuda:0')\n",
      "tensor([41], device='cuda:0')\n",
      "tensor([42], device='cuda:0')\n",
      "tensor([44], device='cuda:0')\n",
      "tensor([47], device='cuda:0')\n",
      "tensor([43], device='cuda:0')\n",
      "tensor([46], device='cuda:0')\n",
      "tensor([34], device='cuda:0')\n",
      "tensor([36], device='cuda:0')\n",
      "tensor([37], device='cuda:0')\n",
      "tensor([40], device='cuda:0')\n",
      "tensor([32], device='cuda:0')\n",
      "tensor([48], device='cuda:0')\n",
      "tensor([28], device='cuda:0')\n",
      "tensor([45], device='cuda:0')\n",
      "tensor([27], device='cuda:0')\n",
      "tensor([25], device='cuda:0')\n",
      "tensor([26], device='cuda:0')\n",
      "tensor([24], device='cuda:0')\n",
      "tensor([23], device='cuda:0')\n",
      "tensor([50], device='cuda:0')\n",
      "tensor([52], device='cuda:0')\n",
      "tensor([57], device='cuda:0')\n",
      "tensor([63], device='cuda:0')\n",
      "tensor([76], device='cuda:0')\n",
      "tensor([71], device='cuda:0')\n",
      "tensor([70], device='cuda:0')\n",
      "tensor([69], device='cuda:0')\n",
      "tensor([77], device='cuda:0')\n",
      "tensor([78], device='cuda:0')\n",
      "tensor([65], device='cuda:0')\n",
      "tensor([62], device='cuda:0')\n",
      "tensor([61], device='cuda:0')\n",
      "tensor([72], device='cuda:0')\n",
      "tensor([73], device='cuda:0')\n",
      "tensor([74], device='cuda:0')\n",
      "tensor([64], device='cuda:0')\n",
      "tensor([67], device='cuda:0')\n",
      "tensor([59], device='cuda:0')\n",
      "tensor([58], device='cuda:0')\n",
      "tensor([80], device='cuda:0')\n",
      "tensor([79], device='cuda:0')\n",
      "tensor([66], device='cuda:0')\n",
      "tensor([49], device='cuda:0')\n",
      "tensor([75], device='cuda:0')\n",
      "tensor([56], device='cuda:0')\n",
      "tensor([55], device='cuda:0')\n",
      "tensor([60], device='cuda:0')\n",
      "tensor([51], device='cuda:0')\n",
      "tensor([68], device='cuda:0')\n",
      "tensor([54], device='cuda:0')\n",
      "tensor([53], device='cuda:0')\n",
      "tensor([85], device='cuda:0')\n",
      "tensor([101], device='cuda:0')\n",
      "tensor([112], device='cuda:0')\n",
      "tensor([111], device='cuda:0')\n",
      "tensor([105], device='cuda:0')\n",
      "tensor([104], device='cuda:0')\n",
      "tensor([99], device='cuda:0')\n",
      "tensor([98], device='cuda:0')\n",
      "tensor([103], device='cuda:0')\n",
      "tensor([106], device='cuda:0')\n",
      "tensor([107], device='cuda:0')\n",
      "tensor([102], device='cuda:0')\n",
      "tensor([100], device='cuda:0')\n",
      "tensor([97], device='cuda:0')\n",
      "tensor([91], device='cuda:0')\n",
      "tensor([90], device='cuda:0')\n",
      "tensor([92], device='cuda:0')\n",
      "tensor([88], device='cuda:0')\n",
      "tensor([96], device='cuda:0')\n",
      "tensor([84], device='cuda:0')\n",
      "tensor([83], device='cuda:0')\n",
      "tensor([94], device='cuda:0')\n",
      "tensor([108], device='cuda:0')\n",
      "tensor([109], device='cuda:0')\n",
      "tensor([110], device='cuda:0')\n",
      "tensor([93], device='cuda:0')\n",
      "tensor([87], device='cuda:0')\n",
      "tensor([89], device='cuda:0')\n",
      "tensor([86], device='cuda:0')\n",
      "tensor([95], device='cuda:0')\n",
      "tensor([82], device='cuda:0')\n",
      "tensor([81], device='cuda:0')\n",
      "tensor([115], device='cuda:0')\n",
      "tensor([114], device='cuda:0')\n",
      "tensor([117], device='cuda:0')\n",
      "tensor([116], device='cuda:0')\n",
      "tensor([124], device='cuda:0')\n",
      "tensor([138], device='cuda:0')\n",
      "tensor([134], device='cuda:0')\n",
      "tensor([133], device='cuda:0')\n",
      "tensor([136], device='cuda:0')\n",
      "tensor([123], device='cuda:0')\n",
      "tensor([126], device='cuda:0')\n",
      "tensor([140], device='cuda:0')\n",
      "tensor([125], device='cuda:0')\n",
      "tensor([135], device='cuda:0')\n",
      "tensor([132], device='cuda:0')\n",
      "tensor([131], device='cuda:0')\n",
      "tensor([129], device='cuda:0')\n",
      "tensor([113], device='cuda:0')\n",
      "tensor([120], device='cuda:0')\n",
      "tensor([137], device='cuda:0')\n",
      "tensor([143], device='cuda:0')\n",
      "tensor([122], device='cuda:0')\n",
      "tensor([118], device='cuda:0')\n",
      "tensor([128], device='cuda:0')\n",
      "tensor([127], device='cuda:0')\n",
      "tensor([121], device='cuda:0')\n",
      "tensor([142], device='cuda:0')\n",
      "tensor([141], device='cuda:0')\n",
      "tensor([130], device='cuda:0')\n",
      "tensor([139], device='cuda:0')\n",
      "tensor([144], device='cuda:0')\n",
      "tensor([119], device='cuda:0')\n",
      "Bot's reply: Here's a short poem for you:\n",
      "\n",
      "In twilight's gentle glow,\n",
      "The world falls asleep,\n",
      "The stars begin to twinkle,\n",
      "A dance of sleep.\n",
      "\n",
      "The wind whispers secrets,\n",
      "Whispers of love and light,\n",
      "The scent of blooming flowers,\n",
      "A symphony of delight.\n",
      "\n",
      "The quiet of the night,\n",
      "A moment to cherish,\n",
      "The beauty of the universe,\n",
      "A sense of peace and stillness.\n",
      "\n",
      "So let's breathe in the silence,\n",
      "And let the stars guide our way,\n",
      "The magic of the night,\n",
      "A testament to the day.\n"
     ]
    }
   ],
   "source": [
    "gen_length = 128\n",
    "steps = 128\n",
    "block_length=128#32\n",
    "print('*' * 66)\n",
    "print(f'**  Answer Length: {gen_length}  |  Sampling Steps: {steps}  **')\n",
    "print('*' * 66)\n",
    "\n",
    "conversation_num = 0\n",
    "user_input = \"Write a poem!\"\n",
    "\n",
    "m = [{\"role\": \"user\", \"content\": user_input}]\n",
    "user_input = tokenizer.apply_chat_template(m, add_generation_prompt=True, tokenize=False)\n",
    "input_ids = tokenizer(user_input)['input_ids']\n",
    "input_ids = torch.tensor(input_ids).to(device).unsqueeze(0)\n",
    "\n",
    "if conversation_num == 0:\n",
    "    prompt = input_ids\n",
    "else:\n",
    "    prompt = torch.cat([prompt, input_ids[:, 1:]], dim=1)\n",
    "\n",
    "out = generate(model, prompt, steps=steps, gen_length=gen_length, block_length=block_length, temperature=0., cfg_scale=0., remasking='predicted')\n",
    "\n",
    "answer = tokenizer.batch_decode(out[:, prompt.shape[1]:], skip_special_tokens=True)[0]\n",
    "print(f\"Bot's reply: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4214c629-360d-4dc4-b871-c14412d63194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28532eb7-3a14-4a2b-ad28-fbb524860ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc2d3e0-413e-4713-b357-6afdb480882d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2748e73d-4411-40d9-938a-7e6b04f00ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|startoftext|>user\\n\\nsay hiassistant\\n\\nHello! How can I assist you today?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([126080, 126346,   3840, 126347,    198,    198,  48851,  26612, 126348, 126346,    598,  10450, 126347,    198,    198,  14455,      0,   2071,560,    331,   6528,    362,   3342,     30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7886402-f9ee-4b85-a6f9-fa8b565cfb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: UNDERSTAND TOKEN STRUCTURE\n",
    "# tensor([[126080, 126346,   3840, 126347,    198,    198,  48851,  26612, 126348,\n",
    "#          126346,    598,  10450, 126347,    198,    198,  14455,      0,   2071,\n",
    "#             560,    331,   6528,    362,   3342,     30, 126348, 126081, 126081,\n",
    "#          126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081,\n",
    "#          126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081,\n",
    "#          126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081,\n",
    "#          126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081,\n",
    "#          126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081,\n",
    "#          126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081,\n",
    "#          126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081,\n",
    "#          126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081,\n",
    "#          126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081,\n",
    "#          126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081,\n",
    "#          126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081,\n",
    "#          126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081,\n",
    "#          126081, 126081, 126081, 126081, 126081, 126081, 126081, 126081]],\n",
    "#        device='cuda:0')\n",
    "# Bot's reply: Hello! How can I assist you today?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
